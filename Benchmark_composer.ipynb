{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73de53e5-9e46-4edd-a64c-9778c3f7285e",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tcapelle/mosaic/blob/master/MosaicML_Composer_and_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a><!--- @wandbcode{mosaicml} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910a2eb0-65b5-4b6c-971a-19bf8121ab13",
   "metadata": {},
   "source": [
    "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<img src=\"https://raw.githubusercontent.com/mosaicml/composer/dev/docs/source/_static/images/header_dark.svg\" width=\"400\" alt=\"mosaicml\" />\n",
    "\n",
    "<!--- @wandbcode{lit_colab_boris} -->\n",
    "\n",
    "# Running fast with MosaicML Composer and Weight and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4961c393-0154-4937-98d7-16e472b9a0d3",
   "metadata": {},
   "source": [
    "[MosaicML Composer](https://docs.mosaicml.com) is a library for training neural networks better, faster, and cheaper. It contains many state-of-the-art methods for accelerating neural network training and improving generalization, along with an optional Trainer API that makes composing many different enhancements easy.\n",
    "\n",
    "Coupled with [Weights & Biases integration](https://docs.mosaicml.com/en/v0.5.0/trainer/logging.html), you can quickly train and monitor models for full traceability and reproducibility with only 2 extra lines of code:\n",
    "\n",
    "```python\n",
    "from composer.loggers import WandBLogger\n",
    "wandb_logger = WandBLogger()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec877f6-57aa-4423-ae4b-f85769c59dd6",
   "metadata": {},
   "source": [
    "W&B integration with Composer can automatically:\n",
    "* log your configuration parameters\n",
    "* log your losses and metrics\n",
    "* log gradients and parameter distributions\n",
    "* log your model\n",
    "* keep track of your code\n",
    "* log your system metrics (GPU, CPU, memory, temperature, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092b0104-530a-438d-bd68-08f627cc8920",
   "metadata": {
    "tags": []
   },
   "source": [
    "### üõ†Ô∏è Installation and set-up\n",
    "\n",
    "We need to install the following libraries:\n",
    "* [mosaicml-composer](https://docs.mosaicml.com/en/v0.5.0/getting_started/installation.html) to set up and train our models\n",
    "* [wandb](https://docs.wandb.ai/) to instrument our training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56bbcb21-babd-488b-a20d-080f43f09897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install wandb mosaicml fastcore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e54ec9-51b6-4f49-9ea1-2ed82f03add3",
   "metadata": {},
   "source": [
    "## Getting Started with Composer üî•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e0f570-d323-4ecf-bdb3-1469730f562b",
   "metadata": {},
   "source": [
    "Composer gives you access to a set of functions to speedup your models and infuse them with state of the art methods. For instance, you can insert [BlurPool](https://docs.mosaicml.com/en/latest/method_cards/blurpool.html) into your CNN by calling `CF.apply_blurpool(model)` into your PyTorch model. Take a look at all the [functional](https://docs.mosaicml.com/en/latest/functional_api.html) methods available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d71a76-7354-43ee-87c1-a83aa88b0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from fastcore.all import *\n",
    "from composer import functional as CF\n",
    "import torchvision.models as models\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "model = models.resnet50()\n",
    "\n",
    "# replace some layers with blurpool\n",
    "CF.apply_blurpool(model);\n",
    "# replace some layers with squeeze-excite\n",
    "CF.apply_squeeze_excite(model, latent_channels=64, min_channels=128);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642eb0d5-b4f6-4add-9d59-235222bc2236",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Using the `Trainer` class with Weights and Biases üèãÔ∏è‚Äç‚ôÄÔ∏è\n",
    "\n",
    "W&B integration with MosaicML-Composer is built into the `Trainer` and can be configured to add extra functionalities through `WandBLogger`:\n",
    "\n",
    "* logging of Artifacts: Use `log_artifacts=True` to log model checkpoints as `wandb.Artifacts`. You can setup how often by passing an int value to `log_artifacts_every_n_batches` (default = 100)\n",
    "* you can also pass any parameter that you would pass to `wandb.init` in `init_params` as a dictionary. For example, you could pass `init_params = {\"project\":\"try_mosaicml\", \"name\":\"benchmark\", \"entity\":\"user_name\"}`.\n",
    "\n",
    "For more details refer to [Logger documentation](https://docs.mosaicml.com/en/latest/api_reference/composer.loggers.wandb_logger.html#composer.loggers.wandb_logger.WandBLogger) and [Wandb docs](https://docs.wandb.ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d98dee3-4a8f-4ac4-b92a-46ea279c9be2",
   "metadata": {},
   "source": [
    "Let's grab fastai's [Imagenette dataset](https://github.com/fastai/imagenette) and decompress it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caecb6eb-25b9-4daf-a1d2-465fecf98ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BS = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b15541-9f20-4979-a24f-145546881641",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path('imagenette2.tgz').exists():\n",
    "    URL = 'https://s3.amazonaws.com/fast-ai-imageclas/imagenette2.tgz'\n",
    "    !wget {URL}\n",
    "    imagenette_path = untar_dir(\"imagenette2.tgz\", Path(\".\"))\n",
    "else:\n",
    "    imagenette_path = Path('imagenette2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222b9eb-4a30-4356-bcd7-38a6f08f1c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "\n",
    "class Imagenette:\n",
    "    def __init__(self, path, train=True, transform=None):\n",
    "        self.path = Path(path) / (\"train\" if train else \"val\")\n",
    "        self.transform = transform\n",
    "        self.files = list(path.glob(\"**/*.JPEG\"))\n",
    "        self.classes = {label.name:i for i, label in enumerate(self.path.iterdir())}\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.files[idx]\n",
    "        image = self.transform(tv.io.read_image(str(file_path), \n",
    "                                             mode=tv.io.image.ImageReadMode.RGB)) \n",
    "        label = self.classes[file_path.parent.name]\n",
    "        return image, label\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbba13-dbb9-436e-8237-fa60f0e54675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from composer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5424e4bf-bd7c-43ff-8a04-2d4e5e13afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_stats = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([T.CenterCrop(256), \n",
    "                                T.ConvertImageDtype(torch.float),\n",
    "                                T.Normalize(*imagenet_stats)\n",
    "                               ])\n",
    "train_dataset = Imagenette(imagenette_path, train=True, transform=transform)\n",
    "eval_dataset = Imagenette(imagenette_path, train=False, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=BS, num_workers=8)\n",
    "eval_dataloader = DataLoader(eval_dataset, batch_size=2*BS, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd120bee-0964-4e8f-8341-491b328ae974",
   "metadata": {},
   "source": [
    "A simple model and the `DecoupledAdamW` optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5656bdcf-399f-408b-8368-a546d0fe6572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "import torch.nn.functional as F\n",
    "from composer.models import ComposerModel\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "class ResNet18(ComposerModel):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.model = resnet18(num_classes=num_classes)\n",
    "        self.train_accuracy = torchmetrics.Accuracy()\n",
    "        self.val_accuracy = torchmetrics.Accuracy()\n",
    "\n",
    "    def forward(self, batch): # batch is the output of the dataloader\n",
    "        # specify how batches are passed through the model\n",
    "        inputs, _ = batch\n",
    "        return self.model(inputs)\n",
    "\n",
    "    def loss(self, outputs, batch):\n",
    "        # pass batches and `forward` outputs to the loss\n",
    "        _, targets = batch\n",
    "        return F.cross_entropy(outputs, targets)\n",
    "    \n",
    "    def validate(self, batch):\n",
    "\n",
    "        inputs, targets = batch\n",
    "        outputs = self.model(inputs)\n",
    "        return outputs, targets\n",
    "    \n",
    "    def metrics(self, train=False):\n",
    "        # defines which metrics to use in each phase of training\n",
    "        return self.train_accuracy if train else self.val_accuracy\n",
    "    \n",
    "model = ResNet18(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa820b1-12bb-43c8-ae7c-5cea24b69c35",
   "metadata": {},
   "source": [
    "we define the `wandb.init` params here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d846b-e438-461f-9346-5818f64a180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.loggers import WandBLogger, TQDMLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4424591-cd28-4af2-987b-be0588a99a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = {\"project\":\"composer\", \n",
    "               \"name\":\"imagenette_baseline\"}\n",
    "\n",
    "# we pass the to the logger \n",
    "wandb_logger = WandBLogger(init_params=init_params)\n",
    "\n",
    "# we also add progressbar logging\n",
    "progress_logger = TQDMLogger()\n",
    "\n",
    "loggers = [progress_logger, wandb_logger]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b5740-7736-4f6d-88f1-c89a669691fe",
   "metadata": {},
   "source": [
    "to tweak what are we logging, we can pass `Callbacks` to the `Trainer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda5f2a-3696-4da0-9197-17076d6dce8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.callbacks import SpeedMonitor, LRMonitor, CheckpointSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e647bcc-abe5-45cd-bb7d-fa91e6c2006e",
   "metadata": {},
   "source": [
    "we include callbacks that measure the model throughput (and the learning rate) and logs them to Weights & Biases. `Callbacks` control what is being logged, whereas loggers specify where the information is being saved. For more information on loggers, see [Logging](https://docs.mosaicml.com/en/latest/trainer/logging.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60c66bc-f046-4a57-9ea7-a6e9fe5cfc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [LRMonitor(),    # Logs the learning rate\n",
    "             SpeedMonitor(), # Logs the training throughput\n",
    "            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1cef41-583b-4915-88f0-a85bd4531206",
   "metadata": {},
   "source": [
    "we can also create a custom callback to log samples to `Weights and Biases` workspace,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c0116c-70e0-4f34-828a-1c911c709346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from composer import Callback, State, Logger\n",
    "\n",
    "class LogPredictions(Callback):\n",
    "    def __init__(self, num_samples=100, seed=1234):\n",
    "        super().__init__()\n",
    "        self.num_samples = num_samples\n",
    "        self.data = []\n",
    "        \n",
    "    def eval_batch_end(self, state: State, logger: Logger):\n",
    "        \"\"\"Compute predictions per batch and stores them on self.data\"\"\"\n",
    "        \n",
    "        if state.timer.epoch == state.max_duration: #on last val epoch\n",
    "            if len(self.data) < self.num_samples:\n",
    "                n = self.num_samples\n",
    "                x, y = state.batch_pair\n",
    "                outputs = state.outputs.argmax(-1)\n",
    "                data = [[wandb.Image(x_i), y_i, y_pred] for x_i, y_i, y_pred in list(zip(x[:n], y[:n], outputs[:n]))]\n",
    "                self.data += data\n",
    "            \n",
    "    def eval_end(self, state: State, logger: Logger):\n",
    "        \"Create a wandb.Table and logs it\"\n",
    "        columns = ['image', 'ground truth', 'prediction']\n",
    "        table = wandb.Table(columns=columns, data=self.data[:self.num_samples])\n",
    "        wandb.log({'sample_table':table}, step=int(state.timer.batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682b52b0-5055-4cfd-a6c1-1a114390e965",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks.append(LogPredictions())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8541c9d6-fc72-46f4-941b-0c4dae64632b",
   "metadata": {},
   "source": [
    "then we pass them to the `Trainer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721f138-3c72-4234-bf14-45235f1d776e",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    optimizers=torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-2),\n",
    "    max_duration=f\"{EPOCHS}ep\",\n",
    "    loggers=loggers,\n",
    "    callbacks=callbacks,\n",
    "    device=\"gpu\",\n",
    "    precision=\"amp\",\n",
    "\n",
    ")\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a36c37-e390-4e86-b2f0-2ec4c390aa80",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Going üöÄ with the Trainer\n",
    "We can try some of the magic algorithms from Mosaic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9a72a3-07cb-4785-a989-be54501a4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composer.algorithms import LabelSmoothing, MixUp, ChannelsLast, ColOut, BlurPool\n",
    "from composer.optim import DecoupledAdamW, CosineAnnealingWithWarmupScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b470b0a-7534-43d2-95bb-fe6850352b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet18(num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c617ebd7-5c82-49f2-8c8e-78fc42986198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optim = DecoupledAdamW(model.parameters(), lr=1e-3)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-2)\n",
    "\n",
    "cosine_annel = CosineAnnealingWithWarmupScheduler('1ep', '1dur')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cdec7f-8e8d-4e4d-a16e-7062b9234695",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = {\"project\":\"composer\", \n",
    "               \"name\":\"imagenette_algos\"}\n",
    "\n",
    "# we pass the to the logger \n",
    "wandb_logger = WandBLogger(init_params=init_params)\n",
    "\n",
    "# we also add progressbar logging\n",
    "progress_logger = TQDMLogger()\n",
    "\n",
    "loggers = [progress_logger, wandb_logger]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066c0b81-8da1-42bf-9682-dfbef156d66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [LRMonitor(),    # Logs the learning rate\n",
    "             SpeedMonitor(), # Logs the training throughput\n",
    "             LogPredictions()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a67bddd-1bc5-4e5c-8e5c-a4f1690f5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms=[LabelSmoothing(), BlurPool()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57da9600-db4b-4a53-84d0-6bafe7daae0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_dataloader,\n",
    "    eval_dataloader=eval_dataloader,\n",
    "    max_duration=f\"{EPOCHS}ep\",\n",
    "    loggers=loggers,\n",
    "    callbacks=callbacks,\n",
    "    optimizers=optim,\n",
    "    schedulers=cosine_annel,\n",
    "    algorithms=algorithms,\n",
    "    precision=\"amp\",\n",
    "    device=\"gpu\",\n",
    ")\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a62cec-c7ab-4f93-9a6e-2f218fff2003",
   "metadata": {},
   "source": [
    "# Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224f92f6-76c6-432b-b17e-9bce07e44644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.wandb import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8ba5ce-bc36-4196-aea4-84a30d7da879",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_folder(imagenette_path, train=\"train\", valid=\"val\", \n",
    "                                   bs=BS, val_bs=2*BS, item_tfms=Resize(256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72e7133-3a67-4ee3-9b3d-586b045b590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=\"composer\", name=\"fastai\"):\n",
    "    cbs = [MixedPrecision(), WandbCallback(log_preds=False)]\n",
    "    learn = cnn_learner(dls, resnet18, metrics=[accuracy], cbs=cbs, pretrained=False)\n",
    "    learn.fit_one_cycle(EPOCHS, 1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
